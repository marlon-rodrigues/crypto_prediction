{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#For Prediction\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, cross_validation\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized  \n",
       "0  66133073.75        12.0                 1200.0  \n",
       "1  62166515.28        12.0                 1200.0  \n",
       "2  44816872.39        12.0                 1200.0  \n",
       "3  35184697.52        12.0                 1200.0  \n",
       "4  21496575.65        12.0                 1200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Datasets \n",
    "research_data_raw = pd.read_csv('Datasets/bitcoin_research_data_v2.csv')\n",
    "# Drop unnecessary columns\n",
    "research_data = research_data_raw.drop('Unnamed: 0', axis=1)\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  \n",
       "0  66133073.75        12.0                 1200.0  1557619199  \n",
       "1  62166515.28        12.0                 1200.0  1557532799  \n",
       "2  44816872.39        12.0                 1200.0  1557446399  \n",
       "3  35184697.52        12.0                 1200.0  1557359999  \n",
       "4  21496575.65        12.0                 1200.0  1557273599  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to milliseconds\n",
    "research_data['Epoch'] = pd.to_datetime(research_data['Date'] + ' 23:59:59.000')\n",
    "research_data['Epoch'] = (research_data['Epoch'] - dt.datetime(1970,1,1)).dt.total_seconds().astype('int64')\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "research_data_imp2 = research_data.copy()\n",
    "research_data_imp2.sort_values(by='Date', inplace=True, ascending=True) # Sort by date ascending\n",
    "forecast_out = int(math.ceil(0.0001 * len(research_data_imp2))) # 0.01% of data\n",
    "#forecast_out = int(math.ceil(0.0025 * len(research_data_imp2))) # 0.05% of data\n",
    "print(len(research_data_imp2))\n",
    "print(forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "      <td>5939.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "      <td>6151.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "      <td>6337.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "      <td>6793.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  Prediction  \n",
       "4  21496575.65        12.0                 1200.0  1557273599      5939.6  \n",
       "3  35184697.52        12.0                 1200.0  1557359999      6151.4  \n",
       "2  44816872.39        12.0                 1200.0  1557446399      6337.9  \n",
       "1  62166515.28        12.0                 1200.0  1557532799      6793.5  \n",
       "0  66133073.75        12.0                 1200.0  1557619199         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_data_imp2['Prediction'] = research_data_imp2['Close'].shift(-forecast_out)\n",
    "research_data_imp2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.array(research_data_imp2.drop(['Prediction', 'Symbol', 'Date', 'Popularity'], 1)) # Create X with numeric columns only\n",
    "    # X = np.array(research_data_imp2['Close'])\n",
    "    # X = research_data_imp2['Close'].to_frame()\n",
    "    X = preprocessing.scale(X)\n",
    "    X_forecast = X[-forecast_out:]\n",
    "    X = X[:-forecast_out]\n",
    "\n",
    "    # research_data_imp2.dropna(inplace=True)\n",
    "\n",
    "    y = np.array(research_data_imp2['Prediction'])\n",
    "    y = y[:-forecast_out]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1445, 8)\n",
      "(1445,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 181,640\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    generator=Sequential()\n",
    "    generator.add(Dense(units=128,input_dim=100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=256))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=8, activation='tanh'))\n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer(), metrics=['accuracy'])\n",
    "    return generator\n",
    "g=create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 168,961\n",
      "Trainable params: 168,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    discriminator=Sequential()\n",
    "    discriminator.add(Dense(units=512,input_dim=8))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    discriminator.add(Dense(units=128))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer(), metrics=['accuracy'])\n",
    "    return discriminator\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_23 (Sequential)   (None, 8)                 181640    \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (None, 1)                 168961    \n",
      "=================================================================\n",
      "Total params: 350,601\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 168,961\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(epoch, generator, examples=100):\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_prices = generator.predict(noise)\n",
    "    \n",
    "    predictions = np.array([p['predictions'][0] for p in generated_prices])\n",
    "\n",
    "    #print(generated_prices)\n",
    "    \n",
    "    # print(\"The Explained Variance: %.2f\" % generator.score(X_test, y_test))  \n",
    "    print(\"The Explained Variance: %.2f\" % metrics.explained_variance_score(y_test, predictions))\n",
    "    print(\"The Mean Absolute Error: %.2f\" % metrics.mean_absolute_error(y_test, predictions))  \n",
    "    print(\"The Median Absolute Error: %.2f\" % metrics.median_absolute_error(y_test, predictions)) \n",
    "    print(\"The Mean Squared Error: %.2f\" % metrics.mean_squared_error(y_test, predictions)) \n",
    "    print(\"The Root Mean Squared Error: %.2f\" % (np.sqrt(metrics.mean_squared_error(y_test, predictions))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    #Loading the data\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    for e in range(1, epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for i in tqdm(range(batch_size)):\n",
    "            #generate  random noise as an input  to  initialize the  generator\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            # Generate fake prices from noised input\n",
    "            generated_prices = generator.predict(noise)\n",
    "            \n",
    "            # Get a random set of real prices\n",
    "            prices_batch = X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            #Construct different batches of real and fake data \n",
    "            X = np.concatenate([prices_batch, generated_prices])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            #Pre train discriminator on fake and real data before starting the gan. \n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            g_loss = gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, g_loss[0], g_loss[1])\n",
    "            print(log_mesg)\n",
    "            \n",
    "        #if e == 1 or e % 20 == 0:\n",
    "        #    get_accuracy(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/128 [00:05<07:59,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [D loss: 0.696894, acc: 0.367188]  [A loss: 0.708449, acc: 0.164062]\n",
      "1: [D loss: 0.693812, acc: 0.289062]  [A loss: 0.698733, acc: 0.421875]\n",
      "2: [D loss: 0.683117, acc: 0.300781]  [A loss: 0.709281, acc: 0.265625]\n",
      "3: [D loss: 0.667386, acc: 0.324219]  [A loss: 0.721694, acc: 0.085938]\n",
      "4: [D loss: 0.665069, acc: 0.382812]  [A loss: 0.729568, acc: 0.093750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/128 [00:05<03:46,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: [D loss: 0.656357, acc: 0.386719]  [A loss: 0.731621, acc: 0.140625]\n",
      "6: [D loss: 0.656095, acc: 0.312500]  [A loss: 0.730667, acc: 0.117188]\n",
      "7: [D loss: 0.659046, acc: 0.308594]  [A loss: 0.730540, acc: 0.179688]\n",
      "8: [D loss: 0.652009, acc: 0.265625]  [A loss: 0.739632, acc: 0.140625]\n",
      "9: [D loss: 0.657711, acc: 0.300781]  [A loss: 0.739354, acc: 0.171875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 16/128 [00:06<01:47,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: [D loss: 0.655306, acc: 0.347656]  [A loss: 0.755558, acc: 0.085938]\n",
      "11: [D loss: 0.663124, acc: 0.351562]  [A loss: 0.751162, acc: 0.085938]\n",
      "12: [D loss: 0.657197, acc: 0.394531]  [A loss: 0.769410, acc: 0.046875]\n",
      "13: [D loss: 0.665863, acc: 0.386719]  [A loss: 0.764789, acc: 0.070312]\n",
      "14: [D loss: 0.664758, acc: 0.363281]  [A loss: 0.781267, acc: 0.039062]\n",
      "15: [D loss: 0.659913, acc: 0.421875]  [A loss: 0.796420, acc: 0.015625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 22/128 [00:06<00:52,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: [D loss: 0.650225, acc: 0.476562]  [A loss: 0.831801, acc: 0.007812]\n",
      "17: [D loss: 0.623184, acc: 0.500000]  [A loss: 0.884327, acc: 0.000000]\n",
      "18: [D loss: 0.598690, acc: 0.500000]  [A loss: 0.966818, acc: 0.000000]\n",
      "19: [D loss: 0.576246, acc: 0.500000]  [A loss: 1.011811, acc: 0.000000]\n",
      "20: [D loss: 0.553025, acc: 0.500000]  [A loss: 1.096665, acc: 0.000000]\n",
      "21: [D loss: 0.544757, acc: 0.500000]  [A loss: 1.167613, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 25/128 [00:06<00:36,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22: [D loss: 0.518895, acc: 0.500000]  [A loss: 1.249085, acc: 0.000000]\n",
      "23: [D loss: 0.493498, acc: 0.500000]  [A loss: 1.348916, acc: 0.000000]\n",
      "24: [D loss: 0.467147, acc: 0.500000]  [A loss: 1.439006, acc: 0.000000]\n",
      "25: [D loss: 0.451860, acc: 0.500000]  [A loss: 1.561634, acc: 0.000000]\n",
      "26: [D loss: 0.423468, acc: 0.500000]  [A loss: 1.598817, acc: 0.000000]\n",
      "27: [D loss: 0.420606, acc: 0.500000]  [A loss: 1.644603, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32/128 [00:06<00:18,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28: [D loss: 0.422660, acc: 0.500000]  [A loss: 1.595044, acc: 0.000000]\n",
      "29: [D loss: 0.447282, acc: 0.500000]  [A loss: 1.473292, acc: 0.000000]\n",
      "30: [D loss: 0.468750, acc: 0.500000]  [A loss: 1.327150, acc: 0.000000]\n",
      "31: [D loss: 0.503971, acc: 0.496094]  [A loss: 1.271762, acc: 0.000000]\n",
      "32: [D loss: 0.510977, acc: 0.476562]  [A loss: 1.154649, acc: 0.015625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 38/128 [00:07<00:10,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33: [D loss: 0.556036, acc: 0.394531]  [A loss: 1.067431, acc: 0.023438]\n",
      "34: [D loss: 0.586661, acc: 0.289062]  [A loss: 0.942015, acc: 0.125000]\n",
      "35: [D loss: 0.636143, acc: 0.187500]  [A loss: 0.792996, acc: 0.296875]\n",
      "36: [D loss: 0.642735, acc: 0.183594]  [A loss: 0.804537, acc: 0.164062]\n",
      "37: [D loss: 0.602043, acc: 0.320312]  [A loss: 0.864692, acc: 0.054688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 44/128 [00:07<00:06, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38: [D loss: 0.552094, acc: 0.460938]  [A loss: 0.992103, acc: 0.015625]\n",
      "39: [D loss: 0.538400, acc: 0.472656]  [A loss: 1.056205, acc: 0.007812]\n",
      "40: [D loss: 0.541913, acc: 0.480469]  [A loss: 1.075992, acc: 0.023438]\n",
      "41: [D loss: 0.543463, acc: 0.425781]  [A loss: 1.015159, acc: 0.031250]\n",
      "42: [D loss: 0.586876, acc: 0.375000]  [A loss: 0.975161, acc: 0.070312]\n",
      "43: [D loss: 0.566592, acc: 0.406250]  [A loss: 1.000226, acc: 0.007812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 47/128 [00:07<00:05, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44: [D loss: 0.526445, acc: 0.500000]  [A loss: 1.083482, acc: 0.000000]\n",
      "45: [D loss: 0.482383, acc: 0.500000]  [A loss: 1.201351, acc: 0.000000]\n",
      "46: [D loss: 0.461634, acc: 0.500000]  [A loss: 1.310053, acc: 0.000000]\n",
      "47: [D loss: 0.452113, acc: 0.500000]  [A loss: 1.290994, acc: 0.000000]\n",
      "48: [D loss: 0.483412, acc: 0.480469]  [A loss: 1.152558, acc: 0.007812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 53/128 [00:07<00:04, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49: [D loss: 0.544236, acc: 0.402344]  [A loss: 1.050722, acc: 0.039062]\n",
      "50: [D loss: 0.583289, acc: 0.296875]  [A loss: 0.895937, acc: 0.101562]\n",
      "51: [D loss: 0.586239, acc: 0.277344]  [A loss: 0.892359, acc: 0.039062]\n",
      "52: [D loss: 0.547538, acc: 0.453125]  [A loss: 1.009049, acc: 0.000000]\n",
      "53: [D loss: 0.521984, acc: 0.476562]  [A loss: 1.084708, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 59/128 [00:07<00:03, 20.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54: [D loss: 0.530019, acc: 0.476562]  [A loss: 1.110983, acc: 0.000000]\n",
      "55: [D loss: 0.490810, acc: 0.500000]  [A loss: 1.228951, acc: 0.000000]\n",
      "56: [D loss: 0.433644, acc: 0.500000]  [A loss: 1.488549, acc: 0.000000]\n",
      "57: [D loss: 0.402426, acc: 0.500000]  [A loss: 1.658675, acc: 0.000000]\n",
      "58: [D loss: 0.371414, acc: 0.500000]  [A loss: 1.855861, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 62/128 [00:08<00:03, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59: [D loss: 0.349062, acc: 0.500000]  [A loss: 1.998095, acc: 0.000000]\n",
      "60: [D loss: 0.352751, acc: 0.500000]  [A loss: 1.990596, acc: 0.000000]\n",
      "61: [D loss: 0.370409, acc: 0.500000]  [A loss: 1.823139, acc: 0.000000]\n",
      "62: [D loss: 0.376710, acc: 0.500000]  [A loss: 1.770010, acc: 0.000000]\n",
      "63: [D loss: 0.337302, acc: 0.500000]  [A loss: 2.022158, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 68/128 [00:08<00:02, 21.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64: [D loss: 0.319746, acc: 0.500000]  [A loss: 2.247343, acc: 0.000000]\n",
      "65: [D loss: 0.303192, acc: 0.500000]  [A loss: 2.392184, acc: 0.000000]\n",
      "66: [D loss: 0.305719, acc: 0.500000]  [A loss: 2.537748, acc: 0.000000]\n",
      "67: [D loss: 0.303090, acc: 0.500000]  [A loss: 2.563425, acc: 0.000000]\n",
      "68: [D loss: 0.278315, acc: 0.500000]  [A loss: 2.421182, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 71/128 [00:08<00:02, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69: [D loss: 0.294186, acc: 0.500000]  [A loss: 2.506985, acc: 0.000000]\n",
      "70: [D loss: 0.278509, acc: 0.500000]  [A loss: 2.653495, acc: 0.000000]\n",
      "71: [D loss: 0.285046, acc: 0.500000]  [A loss: 2.805528, acc: 0.000000]\n",
      "72: [D loss: 0.275141, acc: 0.500000]  [A loss: 2.978531, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 77/128 [00:08<00:02, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73: [D loss: 0.248596, acc: 0.500000]  [A loss: 3.092530, acc: 0.000000]\n",
      "74: [D loss: 0.268550, acc: 0.500000]  [A loss: 3.185229, acc: 0.000000]\n",
      "75: [D loss: 0.249189, acc: 0.500000]  [A loss: 3.211747, acc: 0.000000]\n",
      "76: [D loss: 0.240046, acc: 0.500000]  [A loss: 3.354675, acc: 0.000000]\n",
      "77: [D loss: 0.255987, acc: 0.500000]  [A loss: 3.402773, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 83/128 [00:09<00:01, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78: [D loss: 0.235393, acc: 0.500000]  [A loss: 3.527570, acc: 0.000000]\n",
      "79: [D loss: 0.227396, acc: 0.500000]  [A loss: 3.474604, acc: 0.000000]\n",
      "80: [D loss: 0.224957, acc: 0.500000]  [A loss: 3.617117, acc: 0.000000]\n",
      "81: [D loss: 0.235577, acc: 0.500000]  [A loss: 3.676919, acc: 0.000000]\n",
      "82: [D loss: 0.215349, acc: 0.500000]  [A loss: 3.665329, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 86/128 [00:09<00:01, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83: [D loss: 0.229539, acc: 0.500000]  [A loss: 3.726729, acc: 0.000000]\n",
      "84: [D loss: 0.209788, acc: 0.500000]  [A loss: 3.855848, acc: 0.000000]\n",
      "85: [D loss: 0.214816, acc: 0.500000]  [A loss: 3.932474, acc: 0.000000]\n",
      "86: [D loss: 0.206496, acc: 0.500000]  [A loss: 3.916372, acc: 0.000000]\n",
      "87: [D loss: 0.218605, acc: 0.500000]  [A loss: 4.009481, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 89/128 [00:09<00:01, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88: [D loss: 0.203359, acc: 0.500000]  [A loss: 3.963610, acc: 0.000000]\n",
      "89: [D loss: 0.207015, acc: 0.500000]  [A loss: 4.033175, acc: 0.000000]\n",
      "90: [D loss: 0.206358, acc: 0.500000]  [A loss: 4.114018, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 94/128 [00:09<00:02, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91: [D loss: 0.207067, acc: 0.500000]  [A loss: 4.214462, acc: 0.000000]\n",
      "92: [D loss: 0.200966, acc: 0.500000]  [A loss: 4.234640, acc: 0.000000]\n",
      "93: [D loss: 0.200621, acc: 0.500000]  [A loss: 4.356941, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 96/128 [00:09<00:02, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94: [D loss: 0.209012, acc: 0.500000]  [A loss: 4.330756, acc: 0.000000]\n",
      "95: [D loss: 0.206059, acc: 0.500000]  [A loss: 4.288016, acc: 0.000000]\n",
      "96: [D loss: 0.213984, acc: 0.500000]  [A loss: 4.351828, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 100/128 [00:10<00:02, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97: [D loss: 0.208337, acc: 0.500000]  [A loss: 4.430797, acc: 0.000000]\n",
      "98: [D loss: 0.202622, acc: 0.500000]  [A loss: 4.431766, acc: 0.000000]\n",
      "99: [D loss: 0.199140, acc: 0.500000]  [A loss: 4.525298, acc: 0.000000]\n",
      "100: [D loss: 0.202034, acc: 0.500000]  [A loss: 4.496109, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 106/128 [00:10<00:01, 17.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101: [D loss: 0.192305, acc: 0.500000]  [A loss: 4.652843, acc: 0.000000]\n",
      "102: [D loss: 0.192308, acc: 0.500000]  [A loss: 4.587369, acc: 0.000000]\n",
      "103: [D loss: 0.202875, acc: 0.500000]  [A loss: 4.602758, acc: 0.000000]\n",
      "104: [D loss: 0.203544, acc: 0.500000]  [A loss: 4.722992, acc: 0.000000]\n",
      "105: [D loss: 0.190572, acc: 0.500000]  [A loss: 4.721349, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 109/128 [00:10<00:01, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106: [D loss: 0.191445, acc: 0.500000]  [A loss: 4.728929, acc: 0.000000]\n",
      "107: [D loss: 0.194070, acc: 0.500000]  [A loss: 4.746870, acc: 0.000000]\n",
      "108: [D loss: 0.189215, acc: 0.500000]  [A loss: 4.699286, acc: 0.000000]\n",
      "109: [D loss: 0.201653, acc: 0.500000]  [A loss: 4.892610, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 114/128 [00:10<00:00, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110: [D loss: 0.186316, acc: 0.500000]  [A loss: 4.694408, acc: 0.000000]\n",
      "111: [D loss: 0.190157, acc: 0.500000]  [A loss: 4.819438, acc: 0.000000]\n",
      "112: [D loss: 0.197577, acc: 0.500000]  [A loss: 4.882598, acc: 0.000000]\n",
      "113: [D loss: 0.179137, acc: 0.500000]  [A loss: 4.954740, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 117/128 [00:11<00:00, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114: [D loss: 0.189584, acc: 0.500000]  [A loss: 4.976187, acc: 0.000000]\n",
      "115: [D loss: 0.189445, acc: 0.500000]  [A loss: 5.091339, acc: 0.000000]\n",
      "116: [D loss: 0.194660, acc: 0.500000]  [A loss: 5.063785, acc: 0.000000]\n",
      "117: [D loss: 0.188368, acc: 0.500000]  [A loss: 5.092139, acc: 0.000000]\n",
      "118: [D loss: 0.187685, acc: 0.500000]  [A loss: 5.067763, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 123/128 [00:11<00:00, 20.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119: [D loss: 0.187353, acc: 0.500000]  [A loss: 5.178201, acc: 0.000000]\n",
      "120: [D loss: 0.187104, acc: 0.500000]  [A loss: 5.138374, acc: 0.000000]\n",
      "121: [D loss: 0.185440, acc: 0.500000]  [A loss: 5.148763, acc: 0.000000]\n",
      "122: [D loss: 0.188008, acc: 0.500000]  [A loss: 5.211050, acc: 0.000000]\n",
      "123: [D loss: 0.188621, acc: 0.500000]  [A loss: 5.202879, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:11<00:00, 11.07it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124: [D loss: 0.184073, acc: 0.500000]  [A loss: 5.216177, acc: 0.000000]\n",
      "125: [D loss: 0.185554, acc: 0.500000]  [A loss: 5.295510, acc: 0.000000]\n",
      "126: [D loss: 0.186319, acc: 0.500000]  [A loss: 5.370991, acc: 0.000000]\n",
      "127: [D loss: 0.190668, acc: 0.500000]  [A loss: 5.239561, acc: 0.000000]\n",
      "Epoch 2\n",
      "0: [D loss: 0.192534, acc: 0.500000]  [A loss: 5.256914, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/128 [00:00<00:06, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [D loss: 0.183938, acc: 0.500000]  [A loss: 5.275107, acc: 0.000000]\n",
      "2: [D loss: 0.182704, acc: 0.500000]  [A loss: 5.399303, acc: 0.000000]\n",
      "3: [D loss: 0.182426, acc: 0.500000]  [A loss: 5.405205, acc: 0.000000]\n",
      "4: [D loss: 0.184183, acc: 0.500000]  [A loss: 5.404956, acc: 0.000000]\n",
      "5: [D loss: 0.183664, acc: 0.500000]  [A loss: 5.398088, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/128 [00:00<00:05, 19.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: [D loss: 0.183587, acc: 0.500000]  [A loss: 5.374809, acc: 0.000000]\n",
      "7: [D loss: 0.180940, acc: 0.500000]  [A loss: 5.366179, acc: 0.000000]\n",
      "8: [D loss: 0.184005, acc: 0.500000]  [A loss: 5.503160, acc: 0.000000]\n",
      "9: [D loss: 0.186549, acc: 0.500000]  [A loss: 5.551287, acc: 0.000000]\n",
      "10: [D loss: 0.178353, acc: 0.500000]  [A loss: 5.546906, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 16/128 [00:00<00:05, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11: [D loss: 0.180781, acc: 0.500000]  [A loss: 5.518902, acc: 0.000000]\n",
      "12: [D loss: 0.180532, acc: 0.500000]  [A loss: 5.575468, acc: 0.000000]\n",
      "13: [D loss: 0.178855, acc: 0.500000]  [A loss: 5.682750, acc: 0.000000]\n",
      "14: [D loss: 0.179621, acc: 0.500000]  [A loss: 5.627625, acc: 0.000000]\n",
      "15: [D loss: 0.182725, acc: 0.500000]  [A loss: 5.731447, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 19/128 [00:00<00:05, 21.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: [D loss: 0.176331, acc: 0.500000]  [A loss: 5.712295, acc: 0.000000]\n",
      "17: [D loss: 0.181811, acc: 0.500000]  [A loss: 5.752369, acc: 0.000000]\n",
      "18: [D loss: 0.177127, acc: 0.500000]  [A loss: 5.810215, acc: 0.000000]\n",
      "19: [D loss: 0.180206, acc: 0.500000]  [A loss: 5.757140, acc: 0.000000]\n",
      "20: [D loss: 0.177012, acc: 0.500000]  [A loss: 5.710749, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 25/128 [00:01<00:04, 20.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21: [D loss: 0.176195, acc: 0.500000]  [A loss: 5.672411, acc: 0.000000]\n",
      "22: [D loss: 0.176023, acc: 0.500000]  [A loss: 5.792100, acc: 0.000000]\n",
      "23: [D loss: 0.175312, acc: 0.500000]  [A loss: 5.867105, acc: 0.000000]\n",
      "24: [D loss: 0.177802, acc: 0.500000]  [A loss: 5.893258, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 28/128 [00:01<00:06, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25: [D loss: 0.179784, acc: 0.500000]  [A loss: 5.768264, acc: 0.000000]\n",
      "26: [D loss: 0.177013, acc: 0.500000]  [A loss: 5.980221, acc: 0.000000]\n",
      "27: [D loss: 0.177439, acc: 0.500000]  [A loss: 5.925349, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32/128 [00:01<00:05, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28: [D loss: 0.176475, acc: 0.500000]  [A loss: 5.892244, acc: 0.000000]\n",
      "29: [D loss: 0.177938, acc: 0.500000]  [A loss: 5.908175, acc: 0.000000]\n",
      "30: [D loss: 0.178529, acc: 0.500000]  [A loss: 5.896842, acc: 0.000000]\n",
      "31: [D loss: 0.177276, acc: 0.500000]  [A loss: 6.012647, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 34/128 [00:01<00:06, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: [D loss: 0.178032, acc: 0.500000]  [A loss: 6.084895, acc: 0.000000]\n",
      "33: [D loss: 0.173606, acc: 0.500000]  [A loss: 6.065935, acc: 0.000000]\n",
      "34: [D loss: 0.174654, acc: 0.500000]  [A loss: 5.987974, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 38/128 [00:02<00:06, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35: [D loss: 0.177658, acc: 0.500000]  [A loss: 6.067294, acc: 0.000000]\n",
      "36: [D loss: 0.176087, acc: 0.500000]  [A loss: 6.033322, acc: 0.000000]\n",
      "37: [D loss: 0.174261, acc: 0.500000]  [A loss: 6.147773, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 40/128 [00:02<00:06, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38: [D loss: 0.180268, acc: 0.500000]  [A loss: 6.061758, acc: 0.000000]\n",
      "39: [D loss: 0.173297, acc: 0.500000]  [A loss: 6.119626, acc: 0.000000]\n",
      "40: [D loss: 0.176403, acc: 0.500000]  [A loss: 6.176679, acc: 0.000000]\n",
      "41: [D loss: 0.182174, acc: 0.500000]  [A loss: 6.125070, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 45/128 [00:02<00:05, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42: [D loss: 0.176916, acc: 0.500000]  [A loss: 6.117107, acc: 0.000000]\n",
      "43: [D loss: 0.173330, acc: 0.500000]  [A loss: 6.012609, acc: 0.000000]\n",
      "44: [D loss: 0.174256, acc: 0.500000]  [A loss: 6.191543, acc: 0.000000]\n",
      "45: [D loss: 0.174218, acc: 0.500000]  [A loss: 6.235231, acc: 0.000000]\n",
      "46: [D loss: 0.173834, acc: 0.500000]  [A loss: 6.101784, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 50/128 [00:02<00:05, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47: [D loss: 0.177206, acc: 0.500000]  [A loss: 6.096704, acc: 0.000000]\n",
      "48: [D loss: 0.172085, acc: 0.500000]  [A loss: 6.230295, acc: 0.000000]\n",
      "49: [D loss: 0.172680, acc: 0.500000]  [A loss: 6.131756, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 54/128 [00:03<00:04, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50: [D loss: 0.173934, acc: 0.500000]  [A loss: 6.255019, acc: 0.000000]\n",
      "51: [D loss: 0.175413, acc: 0.500000]  [A loss: 6.166079, acc: 0.000000]\n",
      "52: [D loss: 0.173091, acc: 0.500000]  [A loss: 6.228171, acc: 0.000000]\n",
      "53: [D loss: 0.171285, acc: 0.500000]  [A loss: 6.223615, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 58/128 [00:03<00:04, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54: [D loss: 0.172861, acc: 0.500000]  [A loss: 6.315526, acc: 0.000000]\n",
      "55: [D loss: 0.174345, acc: 0.500000]  [A loss: 6.174391, acc: 0.000000]\n",
      "56: [D loss: 0.171520, acc: 0.500000]  [A loss: 6.220279, acc: 0.000000]\n",
      "57: [D loss: 0.171057, acc: 0.500000]  [A loss: 6.339940, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 63/128 [00:03<00:03, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58: [D loss: 0.173268, acc: 0.500000]  [A loss: 6.305139, acc: 0.000000]\n",
      "59: [D loss: 0.171780, acc: 0.500000]  [A loss: 6.407519, acc: 0.000000]\n",
      "60: [D loss: 0.171562, acc: 0.500000]  [A loss: 6.393921, acc: 0.000000]\n",
      "61: [D loss: 0.171315, acc: 0.500000]  [A loss: 6.228436, acc: 0.000000]\n",
      "62: [D loss: 0.170893, acc: 0.500000]  [A loss: 6.366342, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 66/128 [00:03<00:03, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63: [D loss: 0.170750, acc: 0.500000]  [A loss: 6.530600, acc: 0.000000]\n",
      "64: [D loss: 0.171036, acc: 0.500000]  [A loss: 6.470688, acc: 0.000000]\n",
      "65: [D loss: 0.172523, acc: 0.500000]  [A loss: 6.498321, acc: 0.000000]\n",
      "66: [D loss: 0.171618, acc: 0.500000]  [A loss: 6.574147, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 71/128 [00:04<00:03, 16.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67: [D loss: 0.173510, acc: 0.500000]  [A loss: 6.537852, acc: 0.000000]\n",
      "68: [D loss: 0.174747, acc: 0.500000]  [A loss: 6.474528, acc: 0.000000]\n",
      "69: [D loss: 0.172762, acc: 0.500000]  [A loss: 6.550393, acc: 0.000000]\n",
      "70: [D loss: 0.173468, acc: 0.500000]  [A loss: 6.611504, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 73/128 [00:04<00:03, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71: [D loss: 0.170996, acc: 0.500000]  [A loss: 6.566719, acc: 0.000000]\n",
      "72: [D loss: 0.174244, acc: 0.500000]  [A loss: 6.478636, acc: 0.000000]\n",
      "73: [D loss: 0.172440, acc: 0.500000]  [A loss: 6.528779, acc: 0.000000]\n",
      "74: [D loss: 0.170403, acc: 0.500000]  [A loss: 6.521573, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 78/128 [00:04<00:02, 17.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75: [D loss: 0.171389, acc: 0.500000]  [A loss: 6.632481, acc: 0.000000]\n",
      "76: [D loss: 0.170973, acc: 0.500000]  [A loss: 6.569202, acc: 0.000000]\n",
      "77: [D loss: 0.170164, acc: 0.500000]  [A loss: 6.615639, acc: 0.000000]\n",
      "78: [D loss: 0.170048, acc: 0.500000]  [A loss: 6.638740, acc: 0.000000]\n",
      "79: [D loss: 0.171201, acc: 0.500000]  [A loss: 6.591766, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 84/128 [00:04<00:02, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80: [D loss: 0.173445, acc: 0.500000]  [A loss: 6.618548, acc: 0.000000]\n",
      "81: [D loss: 0.172706, acc: 0.500000]  [A loss: 6.637849, acc: 0.000000]\n",
      "82: [D loss: 0.171544, acc: 0.500000]  [A loss: 6.599769, acc: 0.000000]\n",
      "83: [D loss: 0.170759, acc: 0.500000]  [A loss: 6.509241, acc: 0.000000]\n",
      "84: [D loss: 0.173252, acc: 0.500000]  [A loss: 6.757565, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 89/128 [00:05<00:02, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85: [D loss: 0.171607, acc: 0.500000]  [A loss: 6.716798, acc: 0.000000]\n",
      "86: [D loss: 0.173574, acc: 0.500000]  [A loss: 6.651863, acc: 0.000000]\n",
      "87: [D loss: 0.170456, acc: 0.500000]  [A loss: 6.583259, acc: 0.000000]\n",
      "88: [D loss: 0.169727, acc: 0.500000]  [A loss: 6.675037, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 92/128 [00:05<00:01, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89: [D loss: 0.170193, acc: 0.500000]  [A loss: 6.712594, acc: 0.000000]\n",
      "90: [D loss: 0.171149, acc: 0.500000]  [A loss: 6.703360, acc: 0.000000]\n",
      "91: [D loss: 0.171018, acc: 0.500000]  [A loss: 6.663058, acc: 0.000000]\n",
      "92: [D loss: 0.171968, acc: 0.500000]  [A loss: 6.689722, acc: 0.000000]\n",
      "93: [D loss: 0.169234, acc: 0.500000]  [A loss: 6.740032, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 95/128 [00:05<00:01, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94: [D loss: 0.172137, acc: 0.500000]  [A loss: 6.737158, acc: 0.000000]\n",
      "95: [D loss: 0.170318, acc: 0.500000]  [A loss: 6.632952, acc: 0.000000]\n",
      "96: [D loss: 0.169723, acc: 0.500000]  [A loss: 6.756413, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 100/128 [00:05<00:01, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97: [D loss: 0.170968, acc: 0.500000]  [A loss: 6.800285, acc: 0.000000]\n",
      "98: [D loss: 0.170980, acc: 0.500000]  [A loss: 6.851236, acc: 0.000000]\n",
      "99: [D loss: 0.168888, acc: 0.500000]  [A loss: 6.688480, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 102/128 [00:05<00:01, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: [D loss: 0.169122, acc: 0.500000]  [A loss: 6.833598, acc: 0.000000]\n",
      "101: [D loss: 0.172531, acc: 0.500000]  [A loss: 6.866549, acc: 0.000000]\n",
      "102: [D loss: 0.169756, acc: 0.500000]  [A loss: 6.810151, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 106/128 [00:06<00:01, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103: [D loss: 0.171493, acc: 0.500000]  [A loss: 6.838959, acc: 0.000000]\n",
      "104: [D loss: 0.170440, acc: 0.500000]  [A loss: 6.841759, acc: 0.000000]\n",
      "105: [D loss: 0.170584, acc: 0.500000]  [A loss: 6.873465, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 108/128 [00:06<00:01, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106: [D loss: 0.170750, acc: 0.500000]  [A loss: 6.856606, acc: 0.000000]\n",
      "107: [D loss: 0.169618, acc: 0.500000]  [A loss: 6.789502, acc: 0.000000]\n",
      "108: [D loss: 0.171442, acc: 0.500000]  [A loss: 6.850171, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 112/128 [00:06<00:01, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109: [D loss: 0.169948, acc: 0.500000]  [A loss: 6.905063, acc: 0.000000]\n",
      "110: [D loss: 0.170847, acc: 0.500000]  [A loss: 6.877227, acc: 0.000000]\n",
      "111: [D loss: 0.171621, acc: 0.500000]  [A loss: 6.890107, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 116/128 [00:07<00:00, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112: [D loss: 0.168499, acc: 0.500000]  [A loss: 6.899694, acc: 0.000000]\n",
      "113: [D loss: 0.170442, acc: 0.500000]  [A loss: 6.978239, acc: 0.000000]\n",
      "114: [D loss: 0.169250, acc: 0.500000]  [A loss: 6.964566, acc: 0.000000]\n",
      "115: [D loss: 0.170493, acc: 0.500000]  [A loss: 6.998185, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 121/128 [00:07<00:00, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116: [D loss: 0.170218, acc: 0.500000]  [A loss: 7.086064, acc: 0.000000]\n",
      "117: [D loss: 0.169830, acc: 0.500000]  [A loss: 6.907965, acc: 0.000000]\n",
      "118: [D loss: 0.172285, acc: 0.500000]  [A loss: 6.966505, acc: 0.000000]\n",
      "119: [D loss: 0.171433, acc: 0.500000]  [A loss: 6.994179, acc: 0.000000]\n",
      "120: [D loss: 0.168505, acc: 0.500000]  [A loss: 6.891110, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 123/128 [00:07<00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121: [D loss: 0.169417, acc: 0.500000]  [A loss: 6.964332, acc: 0.000000]\n",
      "122: [D loss: 0.172305, acc: 0.500000]  [A loss: 7.034305, acc: 0.000000]\n",
      "123: [D loss: 0.171182, acc: 0.500000]  [A loss: 6.942657, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:07<00:00, 14.66it/s]\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124: [D loss: 0.170336, acc: 0.500000]  [A loss: 6.945727, acc: 0.000000]\n",
      "125: [D loss: 0.170330, acc: 0.500000]  [A loss: 6.924889, acc: 0.000000]\n",
      "126: [D loss: 0.169078, acc: 0.500000]  [A loss: 7.078965, acc: 0.000000]\n",
      "127: [D loss: 0.170333, acc: 0.500000]  [A loss: 7.027094, acc: 0.000000]\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/128 [00:00<00:10, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [D loss: 0.170214, acc: 0.500000]  [A loss: 6.950431, acc: 0.000000]\n",
      "1: [D loss: 0.170418, acc: 0.500000]  [A loss: 6.988026, acc: 0.000000]\n",
      "2: [D loss: 0.169250, acc: 0.500000]  [A loss: 6.915956, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/128 [00:00<00:09, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: [D loss: 0.169000, acc: 0.500000]  [A loss: 7.126635, acc: 0.000000]\n",
      "4: [D loss: 0.169998, acc: 0.500000]  [A loss: 7.074955, acc: 0.000000]\n",
      "5: [D loss: 0.169803, acc: 0.500000]  [A loss: 7.114731, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 8/128 [00:00<00:09, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: [D loss: 0.168756, acc: 0.500000]  [A loss: 7.088312, acc: 0.000000]\n",
      "7: [D loss: 0.168598, acc: 0.500000]  [A loss: 7.065714, acc: 0.000000]\n",
      "8: [D loss: 0.168483, acc: 0.500000]  [A loss: 7.063274, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 12/128 [00:00<00:08, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: [D loss: 0.169689, acc: 0.500000]  [A loss: 7.095112, acc: 0.000000]\n",
      "10: [D loss: 0.169306, acc: 0.500000]  [A loss: 7.022535, acc: 0.000000]\n",
      "11: [D loss: 0.167913, acc: 0.500000]  [A loss: 7.126123, acc: 0.000000]\n"
     ]
    }
   ],
   "source": [
    "#training(400,128)\n",
    "training(3,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
