{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#For Prediction\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, cross_validation\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized  \n",
       "0  66133073.75        12.0                 1200.0  \n",
       "1  62166515.28        12.0                 1200.0  \n",
       "2  44816872.39        12.0                 1200.0  \n",
       "3  35184697.52        12.0                 1200.0  \n",
       "4  21496575.65        12.0                 1200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Datasets \n",
    "research_data_raw = pd.read_csv('Datasets/bitcoin_research_data_v2.csv')\n",
    "# Drop unnecessary columns\n",
    "research_data = research_data_raw.drop('Unnamed: 0', axis=1)\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  \n",
       "0  66133073.75        12.0                 1200.0  1557619199  \n",
       "1  62166515.28        12.0                 1200.0  1557532799  \n",
       "2  44816872.39        12.0                 1200.0  1557446399  \n",
       "3  35184697.52        12.0                 1200.0  1557359999  \n",
       "4  21496575.65        12.0                 1200.0  1557273599  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to milliseconds\n",
    "research_data['Epoch'] = pd.to_datetime(research_data['Date'] + ' 23:59:59.000')\n",
    "research_data['Epoch'] = (research_data['Epoch'] - dt.datetime(1970,1,1)).dt.total_seconds().astype('int64')\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "research_data_imp2 = research_data.copy()\n",
    "research_data_imp2.sort_values(by='Date', inplace=True, ascending=True) # Sort by date ascending\n",
    "forecast_out = int(math.ceil(0.0001 * len(research_data_imp2))) # 0.01% of data\n",
    "#forecast_out = int(math.ceil(0.0025 * len(research_data_imp2))) # 0.05% of data\n",
    "print(len(research_data_imp2))\n",
    "print(forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "      <td>5939.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "      <td>6151.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "      <td>6337.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "      <td>6793.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  Prediction  \n",
       "4  21496575.65        12.0                 1200.0  1557273599      5939.6  \n",
       "3  35184697.52        12.0                 1200.0  1557359999      6151.4  \n",
       "2  44816872.39        12.0                 1200.0  1557446399      6337.9  \n",
       "1  62166515.28        12.0                 1200.0  1557532799      6793.5  \n",
       "0  66133073.75        12.0                 1200.0  1557619199         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_data_imp2['Prediction'] = research_data_imp2['Close'].shift(-forecast_out)\n",
    "research_data_imp2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.array(research_data_imp2.drop(['Prediction', 'Symbol', 'Date', 'Popularity'], 1)) # Create X with numeric columns only\n",
    "    # X = np.array(research_data_imp2['Close'])\n",
    "    # X = research_data_imp2['Close'].to_frame()\n",
    "    X = preprocessing.scale(X)\n",
    "    X_forecast = X[-forecast_out:]\n",
    "    X = X[:-forecast_out]\n",
    "\n",
    "    # research_data_imp2.dropna(inplace=True)\n",
    "\n",
    "    y = np.array(research_data_imp2['Prediction'])\n",
    "    y = y[:-forecast_out]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1445, 8)\n",
      "(1445,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 181,640\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    generator=Sequential()\n",
    "    generator.add(Dense(units=128,input_dim=100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=256))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=8, activation='tanh'))\n",
    "    \n",
    "    #generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer(), metrics=['accuracy'])\n",
    "    generator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return generator\n",
    "g=create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 168,961\n",
      "Trainable params: 168,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "\n",
    "    discriminator=Sequential()\n",
    "    discriminator.add(Dense(units=512,input_dim=8))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    discriminator.add(Dense(units=128))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return discriminator\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 8)                 181640    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 168961    \n",
      "=================================================================\n",
      "Total params: 350,601\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 168,961\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 8)                 181640    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 168961    \n",
      "=================================================================\n",
      "Total params: 350,601\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 168,961\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan2(d, g):\n",
    "    optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "    AM = Sequential()\n",
    "    AM.add(g)\n",
    "    AM.add(d)\n",
    "    AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "        metrics=['accuracy'])\n",
    "    return AM\n",
    "gan2 = create_gan2(d,g)\n",
    "gan2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(epoch, generator, examples=100):\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_prices = generator.predict(noise)\n",
    "    \n",
    "    predictions = np.array([p['predictions'][0] for p in generated_prices])\n",
    "\n",
    "    #print(generated_prices)\n",
    "    \n",
    "    # print(\"The Explained Variance: %.2f\" % generator.score(X_test, y_test))  \n",
    "    print(\"The Explained Variance: %.2f\" % metrics.explained_variance_score(y_test, predictions))\n",
    "    print(\"The Mean Absolute Error: %.2f\" % metrics.mean_absolute_error(y_test, predictions))  \n",
    "    print(\"The Median Absolute Error: %.2f\" % metrics.median_absolute_error(y_test, predictions)) \n",
    "    print(\"The Mean Squared Error: %.2f\" % metrics.mean_squared_error(y_test, predictions)) \n",
    "    print(\"The Root Mean Squared Error: %.2f\" % (np.sqrt(metrics.mean_squared_error(y_test, predictions))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    #Loading the data\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    #gan = create_gan2(discriminator, generator)\n",
    "    \n",
    "    for e in range(1, epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for i in tqdm(range(batch_size)):\n",
    "            #generate  random noise as an input  to  initialize the  generator\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            # Generate fake prices from noised input\n",
    "            generated_prices = generator.predict(noise)\n",
    "            \n",
    "            # Get a random set of real prices\n",
    "            prices_batch = X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            #Construct different batches of real and fake data \n",
    "            X = np.concatenate([prices_batch, generated_prices])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            #Pre train discriminator on fake and real data before starting the gan. \n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            a_loss = gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "            if i == (batch_size-1):\n",
    "                log_mesg = \"%d: [D loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
    "                log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "                print(log_mesg)\n",
    "            \n",
    "        #if e == 1 or e % 20 == 0:\n",
    "        #    get_accuracy(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:06<00:00, 20.51it/s]\n",
      "  2%|▏         | 3/128 [00:00<00:04, 26.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [D loss: 0.579541, acc: 0.484375]  [A loss: 1.076889, acc: 0.046875]\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:05<00:00, 25.15it/s]\n",
      "  2%|▏         | 2/128 [00:00<00:06, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: [D loss: 0.619725, acc: 0.472656]  [A loss: 1.063460, acc: 0.101562]\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 25.93it/s]\n",
      "  2%|▏         | 3/128 [00:00<00:04, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: [D loss: 0.536381, acc: 0.460938]  [A loss: 1.225457, acc: 0.085938]\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 29.84it/s]\n",
      "  2%|▏         | 3/128 [00:00<00:04, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: [D loss: 0.504877, acc: 0.476562]  [A loss: 1.283607, acc: 0.148438]\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 26.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: [D loss: 0.437042, acc: 0.476562]  [A loss: 1.440132, acc: 0.093750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#training(400,128)\n",
    "training(5,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
