{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.5/dist-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#For Prediction\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing, cross_validation\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input, Conv1D, BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized  \n",
       "0  66133073.75        12.0                 1200.0  \n",
       "1  62166515.28        12.0                 1200.0  \n",
       "2  44816872.39        12.0                 1200.0  \n",
       "3  35184697.52        12.0                 1200.0  \n",
       "4  21496575.65        12.0                 1200.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Datasets \n",
    "research_data_raw = pd.read_csv('Datasets/bitcoin_research_data_v2.csv')\n",
    "# Drop unnecessary columns\n",
    "research_data = research_data_raw.drop('Unnamed: 0', axis=1)\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  \n",
       "0  66133073.75        12.0                 1200.0  1557619199  \n",
       "1  62166515.28        12.0                 1200.0  1557532799  \n",
       "2  44816872.39        12.0                 1200.0  1557446399  \n",
       "3  35184697.52        12.0                 1200.0  1557359999  \n",
       "4  21496575.65        12.0                 1200.0  1557273599  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to milliseconds\n",
    "research_data['Epoch'] = pd.to_datetime(research_data['Date'] + ' 23:59:59.000')\n",
    "research_data['Epoch'] = (research_data['Epoch'] - dt.datetime(1970,1,1)).dt.total_seconds().astype('int64')\n",
    "research_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "research_data_imp2 = research_data.copy()\n",
    "research_data_imp2.sort_values(by='Date', inplace=True, ascending=True) # Sort by date ascending\n",
    "forecast_out = int(math.ceil(0.0001 * len(research_data_imp2))) # 0.01% of data\n",
    "#forecast_out = int(math.ceil(0.0025 * len(research_data_imp2))) # 0.05% of data\n",
    "print(len(research_data_imp2))\n",
    "print(forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume BTC</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Popularity_Normalized</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5955.8</td>\n",
       "      <td>5687.4</td>\n",
       "      <td>5906.7</td>\n",
       "      <td>3668.12</td>\n",
       "      <td>21496575.65</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557273599</td>\n",
       "      <td>5939.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>5983.2</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6007.11</td>\n",
       "      <td>35184697.52</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557359999</td>\n",
       "      <td>6151.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>5939.6</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>5933.2</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>7405.18</td>\n",
       "      <td>44816872.39</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557446399</td>\n",
       "      <td>6337.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6151.4</td>\n",
       "      <td>6430.0</td>\n",
       "      <td>6110.1</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>9872.86</td>\n",
       "      <td>62166515.28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557532799</td>\n",
       "      <td>6793.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6984.8</td>\n",
       "      <td>6337.9</td>\n",
       "      <td>6793.5</td>\n",
       "      <td>9855.87</td>\n",
       "      <td>66133073.75</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1557619199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Symbol    Open    High     Low   Close  Volume BTC  \\\n",
       "4  2019-05-07  BTCUSD  5687.4  5955.8  5687.4  5906.7     3668.12   \n",
       "3  2019-05-08  BTCUSD  5744.0  5983.2  5660.0  5939.6     6007.11   \n",
       "2  2019-05-09  BTCUSD  5939.6  6174.0  5933.2  6151.4     7405.18   \n",
       "1  2019-05-10  BTCUSD  6151.4  6430.0  6110.1  6337.9     9872.86   \n",
       "0  2019-05-11  BTCUSD  6337.9  6984.8  6337.9  6793.5     9855.87   \n",
       "\n",
       "    Volume USD  Popularity  Popularity_Normalized       Epoch  Prediction  \n",
       "4  21496575.65        12.0                 1200.0  1557273599      5939.6  \n",
       "3  35184697.52        12.0                 1200.0  1557359999      6151.4  \n",
       "2  44816872.39        12.0                 1200.0  1557446399      6337.9  \n",
       "1  62166515.28        12.0                 1200.0  1557532799      6793.5  \n",
       "0  66133073.75        12.0                 1200.0  1557619199         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_data_imp2['Prediction'] = research_data_imp2['Close'].shift(-forecast_out)\n",
    "research_data_imp2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.array(research_data_imp2.drop(['Prediction', 'Symbol', 'Date', 'Popularity'], 1)) # Create X with numeric columns only\n",
    "    # X = np.array(research_data_imp2['Close'])\n",
    "    # X = research_data_imp2['Close'].to_frame()\n",
    "    X = preprocessing.scale(X)\n",
    "    X_forecast = X[-forecast_out:]\n",
    "    X = X[:-forecast_out]\n",
    "\n",
    "    # research_data_imp2.dropna(inplace=True)\n",
    "\n",
    "    y = np.array(research_data_imp2['Prediction'])\n",
    "    y = y[:-forecast_out]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1445, 8)\n",
      "(1445,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 181,640\n",
      "Trainable params: 181,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    generator=Sequential()\n",
    "    generator.add(Dense(units=128,input_dim=100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=256))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(units=8, activation='tanh'))\n",
    "    \n",
    "    #generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer(), metrics=['accuracy'])\n",
    "    generator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return generator\n",
    "g=create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 723, 16)           656       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 723, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 362, 64)           5184      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 362, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 362, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 181, 128)          41088     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 181, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 181, 128)          512       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 181, 220)          28380     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 181, 220)          880       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 181, 220)          0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 181, 220)          48620     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 181, 1)            221       \n",
      "=================================================================\n",
      "Total params: 125,797\n",
      "Trainable params: 124,973\n",
      "Non-trainable params: 824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "\n",
    "    discriminator=Sequential()\n",
    "\n",
    "    discriminator.add(Conv1D(32, 5, strides=2, input_shape=(1445, 8), padding='same'))\n",
    "    discriminator.add(LeakyReLU(0.01))\n",
    "    \n",
    "    discriminator.add(Conv1D(64, 5, strides=2, padding='same'))\n",
    "    discriminator.add(LeakyReLU(0.01))\n",
    "    discriminator.add(BatchNormalization(momentum=0.9))\n",
    "    \n",
    "    discriminator.add(Conv1D(128, 5, strides=2, padding='same'))\n",
    "    discriminator.add(LeakyReLU(0.01))\n",
    "    discriminator.add(BatchNormalization(momentum=0.9))\n",
    "   \n",
    "    discriminator.add(Dense(units=220))\n",
    "    discriminator.add(BatchNormalization(momentum=0.9))\n",
    "    discriminator.add(LeakyReLU(0.01))\n",
    "\n",
    "    discriminator.add(Dense(units=220))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "#     ---------------------------------------------------------------\n",
    "#     discriminator.add(Dense(units=512,input_dim=8))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "#     discriminator.add(Dense(units=256))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "       \n",
    "#     discriminator.add(Dense(units=128))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return discriminator\n",
    "\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequential_5_18/dense_8/Tanh:0\", shape=(?, 8), dtype=float32)\n",
      "(?, 8)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-bc3484f25134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-bc3484f25134>\u001b[0m in \u001b[0;36mcreate_gan\u001b[0;34m(discriminator, generator)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgan_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgan_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgan_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m                             output_masks = _to_list(layer.compute_mask(computed_tensor,\n\u001b[1;32m   2238\u001b[0m                                                                        computed_mask))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 dilation_rate=self.dilation_rate[0])\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             outputs = K.conv2d(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3295\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3296\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3297\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         data_format=data_format)\n\u001b[0m\u001b[1;32m    781\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m       \u001b[0minput_channels_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_spatial_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m       \u001b[0mspatial_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    gan_output= discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(epoch, generator, examples=100):\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_prices = generator.predict(noise)\n",
    "    \n",
    "    predictions = np.array([p['predictions'][0] for p in generated_prices])\n",
    "\n",
    "    #print(generated_prices)\n",
    "    \n",
    "    # print(\"The Explained Variance: %.2f\" % generator.score(X_test, y_test))  \n",
    "    print(\"The Explained Variance: %.2f\" % metrics.explained_variance_score(y_test, predictions))\n",
    "    print(\"The Mean Absolute Error: %.2f\" % metrics.mean_absolute_error(y_test, predictions))  \n",
    "    print(\"The Median Absolute Error: %.2f\" % metrics.median_absolute_error(y_test, predictions)) \n",
    "    print(\"The Mean Squared Error: %.2f\" % metrics.mean_squared_error(y_test, predictions)) \n",
    "    print(\"The Root Mean Squared Error: %.2f\" % (np.sqrt(metrics.mean_squared_error(y_test, predictions))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    #Loading the data\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "    #gan = create_gan(discriminator, generator)\n",
    "    gan = create_gan2(discriminator, generator)\n",
    "    \n",
    "    for e in range(1, epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for i in tqdm(range(batch_size)):\n",
    "            #generate  random noise as an input  to  initialize the  generator\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            # Generate fake prices from noised input\n",
    "            generated_prices = generator.predict(noise)\n",
    "            \n",
    "            # Get a random set of real prices\n",
    "            prices_batch = X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            #Construct different batches of real and fake data \n",
    "            X = np.concatenate([prices_batch, generated_prices])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            #Pre train discriminator on fake and real data before starting the gan. \n",
    "            discriminator.trainable = True\n",
    "            d_loss = discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            noise = np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            a_loss = gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "            if i == (batch_size-1):\n",
    "                log_mesg = \"%d: [D loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
    "                log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "                print(log_mesg)\n",
    "            \n",
    "        #if e == 1 or e % 20 == 0:\n",
    "        #    get_accuracy(e, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "100%|██████████| 128/128 [00:06<00:00, 19.87it/s]\n",
      "  2%|▏         | 3/128 [00:00<00:05, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [D loss: 0.653500, acc: 0.234375]  [A loss: 0.759859, acc: 0.226562]\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 28.09it/s]\n",
      "  2%|▏         | 3/128 [00:00<00:04, 26.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: [D loss: 0.629255, acc: 0.417969]  [A loss: 0.906325, acc: 0.054688]\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:04<00:00, 26.29it/s]\n",
      "  2%|▏         | 2/128 [00:00<00:08, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: [D loss: 0.646477, acc: 0.410156]  [A loss: 0.936516, acc: 0.062500]\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 4/128 [00:00<00:08, 13.90it/s]"
     ]
    }
   ],
   "source": [
    "#training(400,128)\n",
    "training(5,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
